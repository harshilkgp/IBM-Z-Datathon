{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYAh6qr2tNA9",
        "outputId": "dfc4aeac-8d41-4c32-ac67-c8ca6a115619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: 'training_set.csv' not found. Please place it in the correct directory.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('training_set.csv')\n",
        "    print(\"Training dataset loaded successfully.\")\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'training_set.csv' not found. Please place it in the correct directory.\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv6HRptyuNxn",
        "outputId": "529f5fea-4272-4cde-a6a0-f3b1293645ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing values per column:\n",
            " Destination Port              0\n",
            " Flow Duration                 0\n",
            " Total Fwd Packets             0\n",
            " Total Backward Packets        0\n",
            "Total Length of Fwd Packets    0\n",
            "                              ..\n",
            "Idle Mean                      0\n",
            " Idle Std                      0\n",
            " Idle Max                      0\n",
            " Idle Min                      0\n",
            " Label                         0\n",
            "Length: 79, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3970738545.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "for col in df.select_dtypes(include=np.number).columns:\n",
        "    df[col].fillna(df[col].mean(), inplace=True)\n",
        "\n",
        "X = df.drop(' Label', axis=1)\n",
        "y = df[' Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBa5xCQGudc9",
        "outputId": "0706ce9d-3b04-4bb0-c397-ed8b2c68ffc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2320834879.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X[col].fillna(X[col].median(), inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Features have been normalized using Min-Max scaling (range 0 to 1).\n"
          ]
        }
      ],
      "source": [
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "for col in X.columns:\n",
        "    if X[col].isnull().any():\n",
        "        X[col].fillna(X[col].median(), inplace=True)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Features have been normalized using Min-Max scaling (range 0 to 1).\")\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "id": "amkFXhnnvPqn",
        "outputId": "9e5f6989-115b-4742-de29-13753f25b65c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Calculated class weights: {0: np.float64(0.6226620947630923), 1: np.float64(2.5381194409148664)}\n",
            "This will penalize errors on the minority class more heavily.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,056</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m5,056\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> (28.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,169\u001b[0m (28.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> (28.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,169\u001b[0m (28.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Model Training with Early Stopping and Checkpointing ---\n",
            "Epoch 1/5\n",
            "\u001b[1m49520/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.1543 - precision_2: 0.7634 - recall_2: 0.9534\n",
            "Epoch 1: val_loss improved from inf to 0.07100, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m49538/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.1543 - precision_2: 0.7634 - recall_2: 0.9534 - val_accuracy: 0.9724 - val_loss: 0.0710 - val_precision_2: 0.8909 - val_recall_2: 0.9801\n",
            "Epoch 2/5\n",
            "\u001b[1m49534/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0893 - precision_2: 0.8635 - recall_2: 0.9743\n",
            "Epoch 2: val_loss did not improve from 0.07100\n",
            "\u001b[1m49538/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 4ms/step - accuracy: 0.9646 - loss: 0.0893 - precision_2: 0.8635 - recall_2: 0.9743 - val_accuracy: 0.9683 - val_loss: 0.0776 - val_precision_2: 0.8687 - val_recall_2: 0.9884\n",
            "Epoch 3/5\n",
            "\u001b[1m49522/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.0808 - precision_2: 0.8744 - recall_2: 0.9789\n",
            "Epoch 3: val_loss improved from 0.07100 to 0.06818, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m49538/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.0808 - precision_2: 0.8744 - recall_2: 0.9789 - val_accuracy: 0.9770 - val_loss: 0.0682 - val_precision_2: 0.9036 - val_recall_2: 0.9886\n",
            "Epoch 4/5\n",
            "\u001b[1m49522/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.0767 - precision_2: 0.8816 - recall_2: 0.9807\n",
            "Epoch 4: val_loss did not improve from 0.06818\n",
            "\u001b[1m49538/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4ms/step - accuracy: 0.9703 - loss: 0.0767 - precision_2: 0.8816 - recall_2: 0.9807 - val_accuracy: 0.9683 - val_loss: 0.0751 - val_precision_2: 0.8694 - val_recall_2: 0.9875\n",
            "Epoch 5/5\n",
            "\u001b[1m49530/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0738 - precision_2: 0.8839 - recall_2: 0.9822\n",
            "Epoch 5: val_loss improved from 0.06818 to 0.06514, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m49538/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 4ms/step - accuracy: 0.9710 - loss: 0.0738 - precision_2: 0.8840 - recall_2: 0.9822 - val_accuracy: 0.9707 - val_loss: 0.0651 - val_precision_2: 0.8795 - val_recall_2: 0.9866\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "--- Model Training Finished ---\n"
          ]
        }
      ],
      "source": [
        "y = y.astype(int)\n",
        "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weights = dict(enumerate(weights))\n",
        "\n",
        "print(f\"\\nCalculated class weights: {class_weights}\")\n",
        "print(\"This will penalize errors on the minority class more heavily.\")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y,\n",
        "    test_size=0.2, \n",
        "    random_state=42,\n",
        "    stratify=y \n",
        ")\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy', \n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    patience=5,          \n",
        "    verbose=1,           \n",
        "    restore_best_weights=True \n",
        ")\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath='best_model.h5',\n",
        "    monitor='val_loss',      \n",
        "    save_best_only=True,    \n",
        "    verbose=1               \n",
        ")\n",
        "print(\"\\n--- Starting Model Training with Early Stopping and Checkpointing ---\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=5, \n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"--- Model Training Finished ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ0ZQN1gI7Qg",
        "outputId": "812b0e72-70ee-46db-ed51-9300fee30c3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12385/12385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step\n",
            "\n",
            "--- Model Evaluation on Validation Set ---\n",
            "Confusion Matrix:\n",
            "[[307679  10555]\n",
            " [  1044  77026]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98    318234\n",
            "           1       0.88      0.99      0.93     78070\n",
            "\n",
            "    accuracy                           0.97    396304\n",
            "   macro avg       0.94      0.98      0.96    396304\n",
            "weighted avg       0.97      0.97      0.97    396304\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_proba = model.predict(X_val)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "print(\"\\n--- Model Evaluation on Validation Set ---\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSN-LdkINdSz",
        "outputId": "ea6ebd82-45ad-4bb3-aca7-8bbf8ded07b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Hold-out test set loaded successfully.\n",
            "--- Applying preprocessing to the test set ---\n",
            "✅ Test set preprocessed identically.\n",
            "\n",
            "--- Generating Final Performance Report ---\n",
            "\u001b[1m26539/26539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step\n",
            "\n",
            "FINAL Classification Report on Unseen Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98    681929\n",
            "           1       0.88      0.99      0.93    167294\n",
            "\n",
            "    accuracy                           0.97    849223\n",
            "   macro avg       0.94      0.98      0.96    849223\n",
            "weighted avg       0.97      0.97      0.97    849223\n",
            "\n",
            "\n",
            "FINAL Confusion Matrix on Unseen Test Data:\n",
            "[[659897  22032]\n",
            " [  2287 165007]]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    test_df = pd.read_csv('test_set.csv')\n",
        "    print(\"Hold-out test set loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'testing_set.csv' not found. Please check the file name.\")\n",
        "    exit()\n",
        "\n",
        "X_test = test_df.drop(' Label', axis=1)\n",
        "y_test = test_df[' Label']\n",
        "\n",
        "print(\"--- Applying preprocessing to the test set ---\")\n",
        "train_cols = X.columns\n",
        "X_test = X_test.reindex(columns=train_cols, fill_value=0)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.fillna(X.median(), inplace=True)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Test set preprocessed identically.\")\n",
        "print(\"\\n--- Generating Final Performance Report ---\")\n",
        "\n",
        "y_test_pred_proba = model.predict(X_test_scaled)\n",
        "y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n",
        "print(\"\\nFINAL Classification Report on Unseen Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(\"\\nFINAL Confusion Matrix on Unseen Test Data:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6mu5dGMdzKv"
      },
      "source": [
        "### SECOND MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU1-JwagZIFA",
        "outputId": "c1a0de87-51af-4b07-a1ef-c3870705e446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset loaded successfully.\n",
            "Dataset shape: (557646, 79)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    df = pd.read_csv('secondary_classification_dataset.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'your_multiclass_dataset.csv' not found. Please check the file name.\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "UGSXylhRgJg3",
        "outputId": "a150ece2-8bf3-475c-cab9-4dc010385cc0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DoS Hulk</th>\n",
              "      <td>231073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PortScan</th>\n",
              "      <td>158930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS</th>\n",
              "      <td>128027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS GoldenEye</th>\n",
              "      <td>10293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTP-Patator</th>\n",
              "      <td>7938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSH-Patator</th>\n",
              "      <td>5897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS slowloris</th>\n",
              "      <td>5796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS Slowhttptest</th>\n",
              "      <td>5499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bot</th>\n",
              "      <td>1966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Web Attack � Brute Force</th>\n",
              "      <td>1507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Web Attack � XSS</th>\n",
              "      <td>652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Infiltration</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Web Attack � Sql Injection</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heartbleed</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              " Label\n",
              "DoS Hulk                      231073\n",
              "PortScan                      158930\n",
              "DDoS                          128027\n",
              "DoS GoldenEye                  10293\n",
              "FTP-Patator                     7938\n",
              "SSH-Patator                     5897\n",
              "DoS slowloris                   5796\n",
              "DoS Slowhttptest                5499\n",
              "Bot                             1966\n",
              "Web Attack � Brute Force        1507\n",
              "Web Attack � XSS                 652\n",
              "Infiltration                      36\n",
              "Web Attack � Sql Injection        21\n",
              "Heartbleed                        11\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[' Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ1j1iWkhW8c",
        "outputId": "a42f11ed-2caa-499a-875a-a4f68733a691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Original Class Distribution ---\n",
            " Label\n",
            "DoS Hulk                      231073\n",
            "PortScan                      158930\n",
            "DDoS                          128027\n",
            "DoS GoldenEye                  10293\n",
            "FTP-Patator                     7938\n",
            "SSH-Patator                     5897\n",
            "DoS slowloris                   5796\n",
            "DoS Slowhttptest                5499\n",
            "Bot                             1966\n",
            "Web Attack � Brute Force        1507\n",
            "Web Attack � XSS                 652\n",
            "Rare_Attack                       47\n",
            "Web Attack � Sql Injection        21\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- New Class Distribution After Grouping ---\n",
            " Label\n",
            "DoS Hulk            231073\n",
            "PortScan            158930\n",
            "DDoS                128027\n",
            "DoS GoldenEye        10293\n",
            "FTP-Patator           7938\n",
            "SSH-Patator           5897\n",
            "DoS slowloris         5796\n",
            "DoS Slowhttptest      5499\n",
            "Web_Attack            2180\n",
            "Bot                   1966\n",
            "Rare_Attack             47\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Original Class Distribution ---\")\n",
        "print(df[' Label'].value_counts())\n",
        "web_attack_map = {\n",
        "    'Web Attack � Brute Force': 'Web_Attack',\n",
        "    'Web Attack � XSS': 'Web_Attack',\n",
        "    'Web Attack � Sql Injection': 'Web_Attack'\n",
        "}\n",
        "\n",
        "rare_attack_map = {\n",
        "    'Infiltration': 'Rare_Attack',\n",
        "    'Heartbleed': 'Rare_Attack'\n",
        "}\n",
        "\n",
        "df[' Label'] = df[' Label'].replace(web_attack_map)\n",
        "df[' Label'] = df[' Label'].replace(rare_attack_map)\n",
        "\n",
        "print(\"\\n--- New Class Distribution After Grouping ---\")\n",
        "print(df[' Label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1MI_8DXi8iW",
        "outputId": "8a33eb4a-78a4-4306-bb5f-b55449eb5604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Distribution Before Final Grouping ---\n",
            " Label\n",
            "DoS Hulk            231073\n",
            "PortScan            158930\n",
            "DDoS                128027\n",
            "DoS GoldenEye        10293\n",
            "FTP-Patator           7938\n",
            "SSH-Patator           5897\n",
            "DoS slowloris         5796\n",
            "DoS Slowhttptest      5499\n",
            "Web_Attack            2180\n",
            "Bot                   1966\n",
            "Rare_Attack             47\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Final, Improved Class Distribution ---\n",
            " Label\n",
            "DoS_Attack      380688\n",
            "PortScan        158930\n",
            "Brute_Force      13835\n",
            "Web_Attack        2180\n",
            "Other_Attack      2013\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Distribution Before Final Grouping ---\")\n",
        "print(df[' Label'].value_counts())\n",
        "\n",
        "dos_map = {\n",
        "    'DoS Hulk': 'DoS_Attack',\n",
        "    'DDoS': 'DoS_Attack',\n",
        "    'DoS GoldenEye': 'DoS_Attack',\n",
        "    'DoS slowloris': 'DoS_Attack',\n",
        "    'DoS Slowhttptest': 'DoS_Attack'\n",
        "}\n",
        "\n",
        "brute_force_map = {\n",
        "    'FTP-Patator': 'Brute_Force',\n",
        "    'SSH-Patator': 'Brute_Force'\n",
        "}\n",
        "\n",
        "other_map = {\n",
        "    'Bot': 'Other_Attack',\n",
        "    'Rare_Attack': 'Other_Attack'\n",
        "}\n",
        "\n",
        "df[' Label'] = df[' Label'].replace(dos_map)\n",
        "df[' Label'] = df[' Label'].replace(brute_force_map)\n",
        "df[' Label'] = df[' Label'].replace(other_map)\n",
        "\n",
        "print(\"\\n--- Final, Improved Class Distribution ---\")\n",
        "print(df[' Label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y90xw42AewKN",
        "outputId": "a7a37e7c-8ae5-4bfb-ffaa-7a2aa5589b96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1765854896.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Missing values handled.\n",
            "Found 5 unique classes.\n"
          ]
        }
      ],
      "source": [
        "for col in df.select_dtypes(include=np.number).columns:\n",
        "    df[col].fillna(df[col].median(), inplace=True)\n",
        "print(\"Missing values handled.\")\n",
        "\n",
        "X = df.drop(' Label', axis=1)\n",
        "y = df[' Label']\n",
        "y, class_names = pd.factorize(y)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Found {num_classes} unique classes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cf0pekijaHs",
        "outputId": "86d4e618-cf7c-4c22-ab0f-7eb753a2ac07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5 unique classes.\n",
            "✅ Labels have been one-hot encoded.\n"
          ]
        }
      ],
      "source": [
        "y, class_names = pd.factorize(y)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Found {num_classes} unique classes.\")\n",
        "\n",
        "y_one_hot = tf.keras.utils.to_categorical(y, num_classes=num_classes)\n",
        "print(\"Labels have been one-hot encoded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyH_resKg-Rv",
        "outputId": "ac2cf5e9-cdcb-4777-8b72-c1f758a91d07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2633925225.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X[col].fillna(X[col].median(), inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Infinite and missing values in features handled.\n",
            "✅ Features have been normalized using Min-Max scaling.\n",
            "Calculated class weights: {0: np.float64(0.2929674694237801), 1: np.float64(0.7017504561756748), 2: np.float64(55.40447093889717), 3: np.float64(51.16018348623853), 4: np.float64(8.06138055655945)}\n",
            "Data split into 446116 training and 111530 validation samples.\n"
          ]
        }
      ],
      "source": [
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "for col in X.columns:\n",
        "    if X[col].isnull().any():\n",
        "        X[col].fillna(X[col].median(), inplace=True)\n",
        "print(\"Infinite and missing values in features handled.\")\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(\"Features have been normalized using Min-Max scaling.\")\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "print(f\"Calculated class weights: {class_weights_dict}\")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y_one_hot,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y \n",
        ")\n",
        "print(f\"Data split into {len(X_train)} training and {len(X_val)} validation samples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "PxbpNIbGjre1",
        "outputId": "d347d8ad-8e03-4479-98d4-28be27aa68f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m10,112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,693</span> (73.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,693\u001b[0m (73.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,693</span> (73.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,693\u001b[0m (73.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Model Training ---\n",
            "Epoch 1/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.4542 - precision: 0.9740 - recall: 0.9005"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 4ms/step - accuracy: 0.9561 - loss: 0.4542 - precision: 0.9740 - recall: 0.9005 - val_accuracy: 0.9911 - val_loss: 0.0643 - val_precision: 0.9926 - val_recall: 0.9908\n",
            "Epoch 2/20\n",
            "\u001b[1m13941/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.1028 - precision: 0.9906 - recall: 0.9876"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.1028 - precision: 0.9906 - recall: 0.9876 - val_accuracy: 0.9952 - val_loss: 0.0383 - val_precision: 0.9954 - val_recall: 0.9951\n",
            "Epoch 3/20\n",
            "\u001b[1m13935/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0947 - precision: 0.9917 - recall: 0.9895"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0946 - precision: 0.9917 - recall: 0.9895 - val_accuracy: 0.9962 - val_loss: 0.0234 - val_precision: 0.9962 - val_recall: 0.9958\n",
            "Epoch 4/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0977 - precision: 0.9919 - recall: 0.9901 - val_accuracy: 0.9953 - val_loss: 0.0363 - val_precision: 0.9955 - val_recall: 0.9953\n",
            "Epoch 5/20\n",
            "\u001b[1m13939/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0967 - precision: 0.9906 - recall: 0.9871"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0967 - precision: 0.9906 - recall: 0.9871 - val_accuracy: 0.9968 - val_loss: 0.0142 - val_precision: 0.9971 - val_recall: 0.9967\n",
            "Epoch 6/20\n",
            "\u001b[1m13936/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0993 - precision: 0.9921 - recall: 0.9899"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0993 - precision: 0.9921 - recall: 0.9899 - val_accuracy: 0.9964 - val_loss: 0.0142 - val_precision: 0.9965 - val_recall: 0.9962\n",
            "Epoch 7/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0958 - precision: 0.9912 - recall: 0.9879 - val_accuracy: 0.9954 - val_loss: 0.0317 - val_precision: 0.9957 - val_recall: 0.9954\n",
            "Epoch 8/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.1399 - precision: 0.9904 - recall: 0.9883 - val_accuracy: 0.9959 - val_loss: 0.0251 - val_precision: 0.9960 - val_recall: 0.9954\n",
            "Epoch 9/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0770 - precision: 0.9926 - recall: 0.9901 - val_accuracy: 0.9964 - val_loss: 0.0158 - val_precision: 0.9969 - val_recall: 0.9963\n",
            "Epoch 10/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0828 - precision: 0.9926 - recall: 0.9895 - val_accuracy: 0.9964 - val_loss: 0.0145 - val_precision: 0.9964 - val_recall: 0.9963\n",
            "Epoch 11/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.1117 - precision: 0.9911 - recall: 0.9882 - val_accuracy: 0.9971 - val_loss: 0.0149 - val_precision: 0.9973 - val_recall: 0.9970\n",
            "--- Model Training Finished ---\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(),\n",
        "        tf.keras.metrics.Recall()\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint(filepath='best_multiclass_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "print(\"\\n--- Starting Model Training ---\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"--- Model Training Finished ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeiLDnebkdDH",
        "outputId": "df3a732d-56cd-4199-aec4-182626ec3087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3486/3486\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
            "\n",
            "--- Model Evaluation on Validation Set ---\n",
            "Confusion Matrix:\n",
            "[[75862     1     2   124   149]\n",
            " [   60 31722     0     4     0]\n",
            " [    1     0   401     0     1]\n",
            " [    6     0     0   391    39]\n",
            " [    6     2     0     2  2757]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  DoS_Attack       1.00      1.00      1.00     76138\n",
            "    PortScan       1.00      1.00      1.00     31786\n",
            "Other_Attack       1.00      1.00      1.00       403\n",
            "  Web_Attack       0.75      0.90      0.82       436\n",
            " Brute_Force       0.94      1.00      0.97      2767\n",
            "\n",
            "    accuracy                           1.00    111530\n",
            "   macro avg       0.94      0.98      0.95    111530\n",
            "weighted avg       1.00      1.00      1.00    111530\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_proba = model.predict(X_val)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "y_true = np.argmax(y_val, axis=1)\n",
        "\n",
        "print(\"\\n--- Model Evaluation on Validation Set ---\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
