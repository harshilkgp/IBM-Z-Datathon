{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 1"
      ],
      "metadata": {
        "id": "HNnoahXCXWuM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYAh6qr2tNA9",
        "outputId": "355c16b6-0ed8-465b-bb5f-e8615c4396e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset loaded successfully.\n",
            "Dataset shape: (1981520, 79)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('training_set.csv')\n",
        "    print(\"Training dataset loaded successfully.\")\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'training_set.csv' not found. Please place it in the correct directory.\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv6HRptyuNxn",
        "outputId": "f38d6cec-c7c8-48f3-86a4-fe773c16d7b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values per column:\n",
            " Destination Port              0\n",
            " Flow Duration                 0\n",
            " Total Fwd Packets             0\n",
            " Total Backward Packets        0\n",
            "Total Length of Fwd Packets    0\n",
            "                              ..\n",
            "Idle Mean                      0\n",
            " Idle Std                      0\n",
            " Idle Max                      0\n",
            " Idle Min                      0\n",
            " Label                         0\n",
            "Length: 79, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-46994758.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "for col in df.select_dtypes(include=np.number).columns:\n",
        "    df[col].fillna(df[col].mean(), inplace=True)\n",
        "\n",
        "X = df.drop(' Label', axis=1)\n",
        "y = df[' Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBa5xCQGudc9",
        "outputId": "a43a96d9-5a76-4d81-b45d-d1882217ba65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3750361215.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X[col].fillna(X[col].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features have been normalized using Min-Max scaling (range 0 to 1).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler1.gz']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "for col in X.columns:\n",
        "    if X[col].isnull().any():\n",
        "        X[col].fillna(X[col].median(), inplace=True)\n",
        "\n",
        "scaler1 = MinMaxScaler()\n",
        "X_scaled = scaler1.fit_transform(X)\n",
        "\n",
        "print(\"Features have been normalized using Min-Max scaling (range 0 to 1).\")\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "joblib.dump(scaler1, 'scaler1.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "id": "amkFXhnnvPqn",
        "outputId": "6cd2bcc9-db85-44f8-803c-9fcccf4e85a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculated class weights: {0: np.float64(0.6226620947630923), 1: np.float64(2.5381194409148664)}\n",
            "This will penalize errors on the minority class more heavily.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m5,056\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,056</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,169\u001b[0m (28.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> (28.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,169\u001b[0m (28.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> (28.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Model Training with Early Stopping and Checkpointing ---\n",
            "Epoch 1/5\n",
            "\u001b[1m49529/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.1506 - precision: 0.7668 - recall: 0.9544\n",
            "Epoch 1: val_loss improved from inf to 0.07889, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m49538/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3ms/step - accuracy: 0.9328 - loss: 0.1506 - precision: 0.7668 - recall: 0.9544 - val_accuracy: 0.9699 - val_loss: 0.0789 - val_precision: 0.8799 - val_recall: 0.9810\n",
            "Epoch 2/5\n",
            "\u001b[1m49532/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.0886 - precision: 0.8592 - recall: 0.9776\n",
            "Epoch 2: val_loss improved from 0.07889 to 0.07072, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m49538/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.0886 - precision: 0.8592 - recall: 0.9776 - val_accuracy: 0.9692 - val_loss: 0.0707 - val_precision: 0.8747 - val_recall: 0.9850\n",
            "Epoch 3/5\n",
            "\u001b[1m49519/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9678 - loss: 0.0791 - precision: 0.8716 - recall: 0.9811\n",
            "Epoch 3: val_loss improved from 0.07072 to 0.06126, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m49538/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3ms/step - accuracy: 0.9678 - loss: 0.0791 - precision: 0.8716 - recall: 0.9811 - val_accuracy: 0.9764 - val_loss: 0.0613 - val_precision: 0.9032 - val_recall: 0.9860\n",
            "Epoch 4/5\n",
            "\u001b[1m49530/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.0763 - precision: 0.8759 - recall: 0.9827\n",
            "Epoch 4: val_loss did not improve from 0.06126\n",
            "\u001b[1m49538/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.0763 - precision: 0.8759 - recall: 0.9827 - val_accuracy: 0.9728 - val_loss: 0.0682 - val_precision: 0.8847 - val_recall: 0.9910\n",
            "Epoch 5/5\n",
            "\u001b[1m49524/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0729 - precision: 0.8807 - recall: 0.9838\n",
            "Epoch 5: val_loss improved from 0.06126 to 0.06125, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m49538/49538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.0729 - precision: 0.8807 - recall: 0.9838 - val_accuracy: 0.9771 - val_loss: 0.0613 - val_precision: 0.9029 - val_recall: 0.9903\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "--- Model Training Finished ---\n"
          ]
        }
      ],
      "source": [
        "y = y.astype(int)\n",
        "\n",
        "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weights = dict(enumerate(weights))\n",
        "\n",
        "print(f\"\\nCalculated class weights: {class_weights}\")\n",
        "print(\"This will penalize errors on the minority class more heavily.\")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath='best_model.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Model Training with Early Stopping and Checkpointing ---\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"--- Model Training Finished ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ0ZQN1gI7Qg",
        "outputId": "6e148ed2-874e-4d18-e1a1-2803aa9c4c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12385/12385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step\n",
            "\n",
            "--- Model Evaluation on Validation Set ---\n",
            "Confusion Matrix:\n",
            "[[309919   8315]\n",
            " [   755  77315]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99    318234\n",
            "           1       0.90      0.99      0.94     78070\n",
            "\n",
            "    accuracy                           0.98    396304\n",
            "   macro avg       0.95      0.98      0.97    396304\n",
            "weighted avg       0.98      0.98      0.98    396304\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_proba = model.predict(X_val)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "print(\"\\n--- Model Evaluation on Validation Set ---\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSN-LdkINdSz",
        "outputId": "cec3a2fc-3855-4d34-9ffc-b09edbdd4b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hold-out test set loaded successfully.\n",
            "--- Applying preprocessing to the test set ---\n",
            "Test set preprocessed identically.\n",
            "\n",
            "--- Generating Final Performance Report ---\n",
            "\u001b[1m26539/26539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step\n",
            "\n",
            "FINAL Classification Report on Unseen Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99    681929\n",
            "           1       0.91      0.99      0.95    167294\n",
            "\n",
            "    accuracy                           0.98    849223\n",
            "   macro avg       0.95      0.98      0.97    849223\n",
            "weighted avg       0.98      0.98      0.98    849223\n",
            "\n",
            "\n",
            "FINAL Confusion Matrix on Unseen Test Data:\n",
            "[[664559  17370]\n",
            " [  1662 165632]]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    test_df = pd.read_csv('test_set.csv')\n",
        "    print(\"Hold-out test set loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'testing_set.csv' not found. Please check the file name.\")\n",
        "    exit()\n",
        "\n",
        "X_test = test_df.drop(' Label', axis=1)\n",
        "y_test = test_df[' Label']\n",
        "print(\"--- Applying preprocessing to the test set ---\")\n",
        "\n",
        "train_cols = X.columns\n",
        "X_test = X_test.reindex(columns=train_cols, fill_value=0)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.fillna(X.median(), inplace=True)\n",
        "X_test_scaled = scaler1.transform(X_test)\n",
        "\n",
        "print(\"Test set preprocessed identically.\")\n",
        "print(\"\\n--- Generating Final Performance Report ---\")\n",
        "\n",
        "y_test_pred_proba = model.predict(X_test_scaled)\n",
        "y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "print(\"\\nFINAL Classification Report on Unseen Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "print(\"\\nFINAL Confusion Matrix on Unseen Test Data:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6mu5dGMdzKv"
      },
      "source": [
        "### MODEL 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU1-JwagZIFA",
        "outputId": "911b9adf-5a83-4dd1-828c-81b0daed5e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "Dataset shape: (557646, 79)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    df = pd.read_csv('secondary_classification_dataset.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'your_multiclass_dataset.csv' not found. Please check the file name.\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "UGSXylhRgJg3",
        "outputId": "b474e0d0-b369-451c-e7d0-ede929061173"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " Label\n",
              "DoS Hulk                      231073\n",
              "PortScan                      158930\n",
              "DDoS                          128027\n",
              "DoS GoldenEye                  10293\n",
              "FTP-Patator                     7938\n",
              "SSH-Patator                     5897\n",
              "DoS slowloris                   5796\n",
              "DoS Slowhttptest                5499\n",
              "Bot                             1966\n",
              "Web Attack � Brute Force        1507\n",
              "Web Attack � XSS                 652\n",
              "Infiltration                      36\n",
              "Web Attack � Sql Injection        21\n",
              "Heartbleed                        11\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DoS Hulk</th>\n",
              "      <td>231073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PortScan</th>\n",
              "      <td>158930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS</th>\n",
              "      <td>128027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS GoldenEye</th>\n",
              "      <td>10293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTP-Patator</th>\n",
              "      <td>7938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSH-Patator</th>\n",
              "      <td>5897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS slowloris</th>\n",
              "      <td>5796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS Slowhttptest</th>\n",
              "      <td>5499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bot</th>\n",
              "      <td>1966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Web Attack � Brute Force</th>\n",
              "      <td>1507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Web Attack � XSS</th>\n",
              "      <td>652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Infiltration</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Web Attack � Sql Injection</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heartbleed</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df[' Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ1j1iWkhW8c",
        "outputId": "71d45cfb-8281-4b1d-c6ed-463fa226923e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Original Class Distribution ---\n",
            " Label\n",
            "DoS Hulk                      231073\n",
            "PortScan                      158930\n",
            "DDoS                          128027\n",
            "DoS GoldenEye                  10293\n",
            "FTP-Patator                     7938\n",
            "SSH-Patator                     5897\n",
            "DoS slowloris                   5796\n",
            "DoS Slowhttptest                5499\n",
            "Bot                             1966\n",
            "Web Attack � Brute Force        1507\n",
            "Web Attack � XSS                 652\n",
            "Infiltration                      36\n",
            "Web Attack � Sql Injection        21\n",
            "Heartbleed                        11\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- New Class Distribution After Grouping ---\n",
            " Label\n",
            "DoS Hulk            231073\n",
            "PortScan            158930\n",
            "DDoS                128027\n",
            "DoS GoldenEye        10293\n",
            "FTP-Patator           7938\n",
            "SSH-Patator           5897\n",
            "DoS slowloris         5796\n",
            "DoS Slowhttptest      5499\n",
            "Web_Attack            2180\n",
            "Bot                   1966\n",
            "Rare_Attack             47\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Original Class Distribution ---\")\n",
        "print(df[' Label'].value_counts())\n",
        "web_attack_map = {\n",
        "    'Web Attack � Brute Force': 'Web_Attack',\n",
        "    'Web Attack � XSS': 'Web_Attack',\n",
        "    'Web Attack � Sql Injection': 'Web_Attack'\n",
        "}\n",
        "\n",
        "rare_attack_map = {\n",
        "    'Infiltration': 'Rare_Attack',\n",
        "    'Heartbleed': 'Rare_Attack'\n",
        "}\n",
        "\n",
        "df[' Label'] = df[' Label'].replace(web_attack_map)\n",
        "df[' Label'] = df[' Label'].replace(rare_attack_map)\n",
        "\n",
        "print(\"\\n--- New Class Distribution After Grouping ---\")\n",
        "print(df[' Label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1MI_8DXi8iW",
        "outputId": "86ea36b0-cc9d-480b-ddc9-bdb37ae1b41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Distribution Before Final Grouping ---\n",
            " Label\n",
            "DoS Hulk            231073\n",
            "PortScan            158930\n",
            "DDoS                128027\n",
            "DoS GoldenEye        10293\n",
            "FTP-Patator           7938\n",
            "SSH-Patator           5897\n",
            "DoS slowloris         5796\n",
            "DoS Slowhttptest      5499\n",
            "Web_Attack            2180\n",
            "Bot                   1966\n",
            "Rare_Attack             47\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Final, Improved Class Distribution ---\n",
            " Label\n",
            "DoS_Attack      380688\n",
            "PortScan        158930\n",
            "Brute_Force      13835\n",
            "Web_Attack        2180\n",
            "Other_Attack      2013\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Distribution Before Final Grouping ---\")\n",
        "print(df[' Label'].value_counts())\n",
        "\n",
        "dos_map = {\n",
        "    'DoS Hulk': 'DoS_Attack',\n",
        "    'DDoS': 'DoS_Attack',\n",
        "    'DoS GoldenEye': 'DoS_Attack',\n",
        "    'DoS slowloris': 'DoS_Attack',\n",
        "    'DoS Slowhttptest': 'DoS_Attack'\n",
        "}\n",
        "\n",
        "brute_force_map = {\n",
        "    'FTP-Patator': 'Brute_Force',\n",
        "    'SSH-Patator': 'Brute_Force'\n",
        "}\n",
        "\n",
        "other_map = {\n",
        "    'Bot': 'Other_Attack',\n",
        "    'Rare_Attack': 'Other_Attack'\n",
        "}\n",
        "df[' Label'] = df[' Label'].replace(dos_map)\n",
        "df[' Label'] = df[' Label'].replace(brute_force_map)\n",
        "df[' Label'] = df[' Label'].replace(other_map)\n",
        "\n",
        "print(\"\\n--- Final, Improved Class Distribution ---\")\n",
        "print(df[' Label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y90xw42AewKN",
        "outputId": "b4e7640e-2d15-4270-9cf1-4feebe8dd580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175202250.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values handled.\n",
            "Found 5 unique classes.\n"
          ]
        }
      ],
      "source": [
        "for col in df.select_dtypes(include=np.number).columns:\n",
        "    df[col].fillna(df[col].median(), inplace=True)\n",
        "print(\"Missing values handled.\")\n",
        "\n",
        "X = df.drop(' Label', axis=1)\n",
        "y = df[' Label']\n",
        "\n",
        "y, class_names = pd.factorize(y)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Found {num_classes} unique classes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cf0pekijaHs",
        "outputId": "0f26b6b5-991e-4597-8683-1143f2b92fa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5 unique classes.\n",
            "Labels have been one-hot encoded.\n"
          ]
        }
      ],
      "source": [
        "y, class_names = pd.factorize(y)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Found {num_classes} unique classes.\")\n",
        "\n",
        "y_one_hot = tf.keras.utils.to_categorical(y, num_classes=num_classes)\n",
        "print(\"Labels have been one-hot encoded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyH_resKg-Rv",
        "outputId": "6deb531e-cb2d-4052-c53e-fa16fdd757e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-97739884.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X[col].fillna(X[col].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infinite and missing values in features handled.\n",
            "Features have been normalized using Min-Max scaling.\n",
            "Calculated class weights: {0: np.float64(0.2929674694237801), 1: np.float64(0.7017504561756748), 2: np.float64(55.40447093889717), 3: np.float64(51.16018348623853), 4: np.float64(8.06138055655945)}\n",
            "Data split into 446116 training and 111530 validation samples.\n"
          ]
        }
      ],
      "source": [
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "for col in X.columns:\n",
        "    if X[col].isnull().any():\n",
        "        X[col].fillna(X[col].median(), inplace=True)\n",
        "print(\"Infinite and missing values in features handled.\")\n",
        "\n",
        "scaler2 = MinMaxScaler()\n",
        "X_scaled = scaler2.fit_transform(X)\n",
        "print(\"Features have been normalized using Min-Max scaling.\")\n",
        "joblib.dump(scaler2, 'scaler2.gz')\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "print(f\"Calculated class weights: {class_weights_dict}\")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y_one_hot,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "print(f\"Data split into {len(X_train)} training and {len(X_val)} validation samples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "id": "PxbpNIbGjre1",
        "outputId": "ed0d7493-e116-4eff-9a40-6812bcd82ae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m10,112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,693\u001b[0m (73.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,693</span> (73.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,693\u001b[0m (73.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,693</span> (73.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Model Training ---\n",
            "Epoch 1/20\n",
            "\u001b[1m13936/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.4488 - precision_1: 0.9761 - recall_1: 0.8943"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4ms/step - accuracy: 0.9534 - loss: 0.4487 - precision_1: 0.9761 - recall_1: 0.8943 - val_accuracy: 0.9964 - val_loss: 0.0300 - val_precision_1: 0.9967 - val_recall_1: 0.9929\n",
            "Epoch 2/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0986 - precision_1: 0.9916 - recall_1: 0.9890"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0986 - precision_1: 0.9916 - recall_1: 0.9890 - val_accuracy: 0.9971 - val_loss: 0.0212 - val_precision_1: 0.9973 - val_recall_1: 0.9969\n",
            "Epoch 3/20\n",
            "\u001b[1m13932/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.1016 - precision_1: 0.9914 - recall_1: 0.9891"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.1016 - precision_1: 0.9914 - recall_1: 0.9891 - val_accuracy: 0.9963 - val_loss: 0.0207 - val_precision_1: 0.9965 - val_recall_1: 0.9960\n",
            "Epoch 4/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0854 - precision_1: 0.9927 - recall_1: 0.9908 - val_accuracy: 0.9960 - val_loss: 0.0314 - val_precision_1: 0.9964 - val_recall_1: 0.9956\n",
            "Epoch 5/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0896 - precision_1: 0.9933 - recall_1: 0.9915 - val_accuracy: 0.9949 - val_loss: 0.0394 - val_precision_1: 0.9951 - val_recall_1: 0.9946\n",
            "Epoch 6/20\n",
            "\u001b[1m13938/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0838 - precision_1: 0.9930 - recall_1: 0.9904"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0838 - precision_1: 0.9930 - recall_1: 0.9904 - val_accuracy: 0.9963 - val_loss: 0.0198 - val_precision_1: 0.9964 - val_recall_1: 0.9962\n",
            "Epoch 7/20\n",
            "\u001b[1m13930/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0858 - precision_1: 0.9928 - recall_1: 0.9903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0858 - precision_1: 0.9928 - recall_1: 0.9903 - val_accuracy: 0.9971 - val_loss: 0.0130 - val_precision_1: 0.9979 - val_recall_1: 0.9970\n",
            "Epoch 8/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0815 - precision_1: 0.9944 - recall_1: 0.9918 - val_accuracy: 0.9964 - val_loss: 0.0148 - val_precision_1: 0.9964 - val_recall_1: 0.9962\n",
            "Epoch 9/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0984 - precision_1: 0.9933 - recall_1: 0.9902 - val_accuracy: 0.9968 - val_loss: 0.0222 - val_precision_1: 0.9969 - val_recall_1: 0.9965\n",
            "Epoch 10/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0746 - precision_1: 0.9938 - recall_1: 0.9904 - val_accuracy: 0.9965 - val_loss: 0.0144 - val_precision_1: 0.9967 - val_recall_1: 0.9965\n",
            "Epoch 11/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.1068 - precision_1: 0.9940 - recall_1: 0.9916 - val_accuracy: 0.9961 - val_loss: 0.0274 - val_precision_1: 0.9962 - val_recall_1: 0.9955\n",
            "Epoch 12/20\n",
            "\u001b[1m13942/13942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0898 - precision_1: 0.9946 - recall_1: 0.9914 - val_accuracy: 0.9961 - val_loss: 0.0217 - val_precision_1: 0.9962 - val_recall_1: 0.9959\n",
            "--- Model Training Finished ---\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(),\n",
        "        tf.keras.metrics.Recall()\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint(filepath='best_multiclass_model.h5', monitor='val_loss', save_best_only=True)\n",
        "print(\"\\n--- Starting Model Training ---\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"--- Model Training Finished ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeiLDnebkdDH",
        "outputId": "e5f71c48-3e97-4e3b-c4bd-47b471e22844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3486/3486\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
            "\n",
            "--- Model Evaluation on Validation Set ---\n",
            "Confusion Matrix:\n",
            "[[75932     0    24    34   148]\n",
            " [   47 31722     0     4    13]\n",
            " [    1     0   401     0     1]\n",
            " [    7     0     0   390    39]\n",
            " [    9     0     0     2  2756]]\n"
          ]
        }
      ],
      "source": [
        "y_pred_proba = model.predict(X_val)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "y_true = np.argmax(y_val, axis=1)\n",
        "\n",
        "print(\"\\n--- Model Evaluation on Validation Set ---\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax4b3vwRJVWa"
      },
      "source": [
        "### SAMPLE TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y80ICqpAOs8",
        "outputId": "fb2421d1-2bcf-4d8b-f100-c0f1c139253a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infinite and missing values in features handled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3590754152.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X[col].fillna(X[col].median(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "df=pd.read_csv('secondary_classification_dataset.csv')\n",
        "X=df.drop(\" Label\",axis=1)\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "for col in X.columns:\n",
        "    if X[col].isnull().any():\n",
        "        X[col].fillna(X[col].median(), inplace=True)\n",
        "print(\"Infinite and missing values in features handled.\")\n",
        "X_scaled_df = pd.DataFrame(X, columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgExViWfCf-5",
        "outputId": "91f62219-e7e9-4708-d637-c78320a37eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Values of the first row as a list:\n",
            "[80.0, 1293792.0, 3.0, 7.0, 26.0, 11607.0, 20.0, 0.0, 8.666666667, 10.26320288, 5840.0, 0.0, 1658.142857, 2137.29708, 8991.398927, 7.72921768, 143754.6667, 430865.8067, 1292730.0, 2.0, 747.0, 373.5, 523.9661249, 744.0, 3.0, 1293746.0, 215624.3333, 527671.9348, 1292730.0, 2.0, 0.0, 0.0, 0.0, 0.0, 72.0, 152.0, 2.318765304, 5.410452376, 0.0, 5840.0, 1057.545455, 1853.437529, 3435230.673, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1163.3, 8.666666667, 1658.142857, 72.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 26.0, 7.0, 11607.0, 8192.0, 229.0, 2.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "first_row_list = X_scaled_df.iloc[0].values.tolist()\n",
        "\n",
        "print(\"\\nValues of the first row as a list:\")\n",
        "print(first_row_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQoTomarD3up",
        "outputId": "0c3cfbb6-058f-4779-8fb8-f2e432798d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded successfully.\n",
            "Scalers loaded successfully.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "\n",
            "Model 1 (Binary) raw output: 1.0000\n",
            "Attack detected. Proceeding to Stage 2 for multiclass classification...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
            "\n",
            "Model 2 (Multiclass) raw output (probabilities): [9.9997735e-01 2.2688186e-05 2.2147821e-09 2.6475639e-09 4.8972613e-16]\n",
            "Final Predicted Class Index: 0\n"
          ]
        }
      ],
      "source": [
        "model1 = load_model('best_model.h5', compile=False)\n",
        "model2 = load_model('best_multiclass_model.h5', compile=False)\n",
        "print(\"Models loaded successfully.\")\n",
        "\n",
        "try:\n",
        "    scaler1 = joblib.load('scaler1.gz')\n",
        "    scaler2 = joblib.load('scaler2.gz')\n",
        "    print(\"Scalers loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Scaler files not found. Please ensure 'scaler1.gz' and 'scaler2.gz' exist.\")\n",
        "    exit()\n",
        "\n",
        "x_raw = np.array([first_row_list])\n",
        "x_input_scaled1 = scaler1.transform(x_raw)\n",
        "output1 = model1.predict(x_input_scaled1)\n",
        "print(f\"\\nModel 1 (Binary) raw output: {output1[0][0]:.4f}\")\n",
        "\n",
        "if output1[0][0] > 0.5:\n",
        "    print(\"Attack detected. Proceeding to Stage 2 for multiclass classification...\")\n",
        "    x_input_scaled2 = scaler2.transform(x_raw)\n",
        "    output2 = model2.predict(x_input_scaled2)\n",
        "    predicted_class_index = np.argmax(output2, axis=1)[0]\n",
        "\n",
        "    print(f\"\\nModel 2 (Multiclass) raw output (probabilities): {output2[0]}\")\n",
        "    print(f\"Final Predicted Class Index: {predicted_class_index}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nResult: Benign data. No further action needed.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}